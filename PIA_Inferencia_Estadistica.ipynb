{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PIA_Inferencia_Estadistica",
      "provenance": [],
      "collapsed_sections": [
        "fWN-N96IAhcm",
        "ne17-6zbAWKQ",
        "yPEuKQgPChik",
        "LNCrMuT6S3y2",
        "QZNNRl8IUdWY",
        "vw9fupdwIGA0"
      ],
      "authorship_tag": "ABX9TyNE1fQLDkDGPwGywmf1ymfo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OviedoMarco/DataScience/blob/MENU/PIA_Inferencia_Estadistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBkK-G9MZIPH"
      },
      "source": [
        "<h1 align=\"center\"> Estadistica Inferencial</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giTQJqt4UhYo"
      },
      "source": [
        "\n",
        "\n",
        "<h2>Before Starting: </h2>\n",
        "Just wanted to note that this work is not finished yet and will be constantly updated, I find that having a basic understanding in the field of Statistics is essential for Data Scientists so I decided to share a bit of that basic knowledge with the Kaggle community. If you would like to see more, upvote so I know that the community is interested in understanding the essential concepts of Statistics. Thanks and have a great day! <br><br>\n",
        "\n",
        "<h2> Introduction: </h2> \n",
        "In this project we will explore the basic of statistical analysis and why it is important to use it in subjects such as data science. When I started working with kernels I've always heard about concepts such as <b> outliers </b> , <b> Interquartile Range (IQR) </b>, <b> hypothesis testing </b> among many others. My main aim in this simple statistical tutorial is finding out the why we need to know such concepts when performing statistical analysis. I started learning R a couple of months ago and I have found that for performing this task doing it in R tends to be more intuitive. However, Python has really good libraries such as stasmodels or the scipy stats library.\n",
        "\n",
        "\n",
        "\n",
        "<h3> Outline: </h3>\n",
        "I. <b>Statistics Basics </b> <br>\n",
        "a)[ Summaries and Histograms](#summary) <br>\n",
        "b) [The relationship between mean and median](#mean_median) <br>\n",
        "c) [Boxplots and Suspected Outliers](#boxplots) <br>\n",
        "d) [Using natural logarithms and Qplots](#qplots) <br><br>\n",
        "\n",
        "\n",
        "II. <b>Inferential Statistics</b> <br>\n",
        "a) [Hypothesis testing and Confidence Intervals](#hypothesis_testing) <br>\n",
        "b) [Interpreting Confidence Intervals](#confidence_intervals) <br>\n",
        "c) [Significance levels and P-values.](#p_val) <br>\n",
        "d)[ Brief Introduction to Chi-Squared Test of Independence (will be continue)](#chi_s) <br>\n",
        "e) [Contingency Tables for Categorical Variables](#contingency)<br>\n",
        "f) [T-Distribution](#t_distribution) <br>\n",
        "g) [Difference Between two Independent Means](#two_independent)<br>\n",
        "h) [Difference Between more than two Independent Mean (ANOVA)](#anova) <br>\n",
        "i) [Bootstrapping (Simulation base method)](#bootstrapping)<br><br>\n",
        "\n",
        "\n",
        "III.  Other Statistics <br>\n",
        "a) [Mosaic Plots and Contingency Tables](#mosaic)\n",
        "b. [Chloropeth Maps with GGPlot2](#us_map)\n",
        "\n",
        "<h3> References: </h3>\n",
        "a) <a href=\"http://www.statisticshowto.com/\"> Statistics Terminology </a><br>\n",
        "b) <a href=\"https://www.kaggle.com/ruslankl/bio-statistics-in-r-part-1\">(Bio)statistics in R: Part #1\n",
        " </a> by def me <br>\n",
        " c) <a href=\"https://www.coursera.org/specializations/statistics\"> Statistics with R </a> Coursera Certification by Duke University <br>\n",
        " d) <a href=\"https://www.youtube.com/watch?v=TP6r5CTd9yM\">Performing the Non-parametric Bootstrap for statistical inference using R </a> by Ian Dworkin\n",
        " e) <a href=\"https://www.datacamp.com/tracks/data-visualization-with-r\"> Data visualization with ggplot Part 2 </a> by Rick Scavetta <br>\n",
        " f) <a href=\"https://stats.stackexchange.com/questions/149219/what-is-the-definition-of-expected-counts-in-chi-square-tests\"> Stack Exchange Reply</a> by Penguin_Knight<br>\n",
        " g) <a href=\"http://rpubs.com/zach_loertscher/406399\"> Outlier Detection </a> by Zach Loertscher\n",
        " \n",
        " \n",
        " <h3>Special Thanks Note: </h3>\n",
        " Special thanks to <b>Alexander Geiger </b> from Golden Oak Research for uploading this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0MVPuKIUhYt",
        "outputId": "1207c9ce-15cf-4607-ddc1-e841472df96b"
      },
      "source": [
        "# Loading Libraries\n",
        "if (!require(\"pacman\")) install.packages(\"pacman\") \n",
        "pacman::p_load(tidyverse, skimr, GGally, plotly, viridis, caret, randomForest, e1071, rpart, \n",
        "               xgboost, h2o, corrplot, rpart.plot, corrgram, lightgbm, ggplot2, highcharter, \n",
        "               ggthemes, psych, scales, treemap, treemapify, repr, cowplot, magrittr, ggpubr,\n",
        "               RColorBrewer, plotrix, ggrepel, tidyverse, gridExtra, reshape2, janitor)\n",
        "\n",
        "lst <- c(\n",
        "    \"tidyverse\", \"skimr\", \"GGally\", \"plotly\", \"viridis\", \"caret\", \"randomForest\", \"e1071\", \"rpart\", \n",
        "               \"xgboost\", \"h2o\", \"corrplot\", \"rpart.plot\", \"corrgram\", \"lightgbm\", \"ggplot2\", \"highcharter\", \n",
        "               \"ggthemes\", \"psych\", \"scales\", \"treemap\", \"treemapify\", \"repr\", \"cowplot\", \"magrittr\", \"ggpubr\",\n",
        "               \"RColorBrewer\", \"plotrix\", \"ggrepel\", \"tidyverse\", \"gridExtra\", \"reshape2\", \"janitor\", \"descr\", \"dplyr\",\"boot\",\"maps\", \"tidyquant\",\n",
        "    \"wesanderson\"\n",
        ")\n",
        "\n",
        "as_tibble(installed.packages())  %>% select(Package, Version)  %>% filter(Package %in% lst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading required package: pacman\n",
            "\n",
            "Warning message in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE, :\n",
            "“there is no package called ‘pacman’”\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "skimr installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘plyr’, ‘reshape’\n",
            "\n",
            "\n",
            "\n",
            "GGally installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘later’, ‘htmlwidgets’, ‘lazyeval’, ‘crosstalk’, ‘promises’\n",
            "\n",
            "\n",
            "\n",
            "plotly installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘gridExtra’\n",
            "\n",
            "\n",
            "\n",
            "viridis installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘listenv’, ‘parallelly’, ‘future’, ‘globals’, ‘future.apply’, ‘progressr’, ‘numDeriv’, ‘SQUAREM’, ‘lava’, ‘prodlim’, ‘iterators’, ‘gower’, ‘ipred’, ‘timeDate’, ‘foreach’, ‘ModelMetrics’, ‘pROC’, ‘recipes’, ‘reshape2’\n",
            "\n",
            "\n",
            "\n",
            "caret installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "randomForest installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "xgboost installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘bitops’, ‘RCurl’\n",
            "\n",
            "\n",
            "\n",
            "h2o installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "corrplot installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "rpart.plot installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "corrgram installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "lightgbm installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘XML’, ‘TTR’, ‘rlist’, ‘zoo’, ‘xts’, ‘quantmod’, ‘igraph’, ‘rjson’\n",
            "\n",
            "\n",
            "\n",
            "highcharter installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘tmvnsim’, ‘mnormt’\n",
            "\n",
            "\n",
            "\n",
            "psych installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘sass’, ‘httpuv’, ‘xtable’, ‘fontawesome’, ‘sourcetools’, ‘bslib’, ‘gridBase’, ‘shiny’\n",
            "\n",
            "\n",
            "\n",
            "treemap installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘shades’, ‘ggfittext’\n",
            "\n",
            "\n",
            "\n",
            "treemapify installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘matrixStats’, ‘RcppArmadillo’, ‘SparseM’, ‘MatrixModels’, ‘conquer’, ‘sp’, ‘openxlsx’, ‘minqa’, ‘nloptr’, ‘RcppEigen’, ‘carData’, ‘abind’, ‘pbkrtest’, ‘quantreg’, ‘maptools’, ‘rio’, ‘lme4’, ‘car’, ‘ggrepel’, ‘ggsci’, ‘ggsignif’, ‘polynom’, ‘rstatix’\n",
            "\n",
            "\n",
            "\n",
            "ggpubr installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "\n",
            "plotrix installed\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘snakecase’\n",
            "\n",
            "\n",
            "\n",
            "janitor installed\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A tibble: 36 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th scope=col>Package</th><th scope=col>Version</th></tr>\n",
              "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><td>caret       </td><td>6.0-90  </td></tr>\n",
              "\t<tr><td>corrgram    </td><td>1.14    </td></tr>\n",
              "\t<tr><td>corrplot    </td><td>0.90    </td></tr>\n",
              "\t<tr><td>cowplot     </td><td>1.1.1   </td></tr>\n",
              "\t<tr><td>dplyr       </td><td>1.0.7   </td></tr>\n",
              "\t<tr><td>e1071       </td><td>1.7-9   </td></tr>\n",
              "\t<tr><td>GGally      </td><td>2.1.2   </td></tr>\n",
              "\t<tr><td>ggplot2     </td><td>3.3.5   </td></tr>\n",
              "\t<tr><td>ggpubr      </td><td>0.4.0   </td></tr>\n",
              "\t<tr><td>ggrepel     </td><td>0.9.1   </td></tr>\n",
              "\t<tr><td>ggthemes    </td><td>4.2.4   </td></tr>\n",
              "\t<tr><td>gridExtra   </td><td>2.3     </td></tr>\n",
              "\t<tr><td>h2o         </td><td>3.34.0.3</td></tr>\n",
              "\t<tr><td>highcharter </td><td>0.8.2   </td></tr>\n",
              "\t<tr><td>janitor     </td><td>2.1.0   </td></tr>\n",
              "\t<tr><td>lightgbm    </td><td>3.3.1   </td></tr>\n",
              "\t<tr><td>plotly      </td><td>4.10.0  </td></tr>\n",
              "\t<tr><td>plotrix     </td><td>3.8-2   </td></tr>\n",
              "\t<tr><td>psych       </td><td>2.1.9   </td></tr>\n",
              "\t<tr><td>randomForest</td><td>4.6-14  </td></tr>\n",
              "\t<tr><td>repr        </td><td>1.1.3   </td></tr>\n",
              "\t<tr><td>reshape2    </td><td>1.4.4   </td></tr>\n",
              "\t<tr><td>rpart.plot  </td><td>3.1.0   </td></tr>\n",
              "\t<tr><td>skimr       </td><td>2.1.3   </td></tr>\n",
              "\t<tr><td>treemap     </td><td>2.4-3   </td></tr>\n",
              "\t<tr><td>treemapify  </td><td>2.5.5   </td></tr>\n",
              "\t<tr><td>viridis     </td><td>0.6.2   </td></tr>\n",
              "\t<tr><td>xgboost     </td><td>1.4.1.1 </td></tr>\n",
              "\t<tr><td>dplyr       </td><td>1.0.7   </td></tr>\n",
              "\t<tr><td>ggplot2     </td><td>3.3.5   </td></tr>\n",
              "\t<tr><td>magrittr    </td><td>2.0.1   </td></tr>\n",
              "\t<tr><td>RColorBrewer</td><td>1.1-2   </td></tr>\n",
              "\t<tr><td>scales      </td><td>1.1.1   </td></tr>\n",
              "\t<tr><td>tidyverse   </td><td>1.3.1   </td></tr>\n",
              "\t<tr><td>boot        </td><td>1.3-28  </td></tr>\n",
              "\t<tr><td>rpart       </td><td>4.1-15  </td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": "A tibble: 36 × 2\n\\begin{tabular}{ll}\n Package & Version\\\\\n <chr> & <chr>\\\\\n\\hline\n\t caret        & 6.0-90  \\\\\n\t corrgram     & 1.14    \\\\\n\t corrplot     & 0.90    \\\\\n\t cowplot      & 1.1.1   \\\\\n\t dplyr        & 1.0.7   \\\\\n\t e1071        & 1.7-9   \\\\\n\t GGally       & 2.1.2   \\\\\n\t ggplot2      & 3.3.5   \\\\\n\t ggpubr       & 0.4.0   \\\\\n\t ggrepel      & 0.9.1   \\\\\n\t ggthemes     & 4.2.4   \\\\\n\t gridExtra    & 2.3     \\\\\n\t h2o          & 3.34.0.3\\\\\n\t highcharter  & 0.8.2   \\\\\n\t janitor      & 2.1.0   \\\\\n\t lightgbm     & 3.3.1   \\\\\n\t plotly       & 4.10.0  \\\\\n\t plotrix      & 3.8-2   \\\\\n\t psych        & 2.1.9   \\\\\n\t randomForest & 4.6-14  \\\\\n\t repr         & 1.1.3   \\\\\n\t reshape2     & 1.4.4   \\\\\n\t rpart.plot   & 3.1.0   \\\\\n\t skimr        & 2.1.3   \\\\\n\t treemap      & 2.4-3   \\\\\n\t treemapify   & 2.5.5   \\\\\n\t viridis      & 0.6.2   \\\\\n\t xgboost      & 1.4.1.1 \\\\\n\t dplyr        & 1.0.7   \\\\\n\t ggplot2      & 3.3.5   \\\\\n\t magrittr     & 2.0.1   \\\\\n\t RColorBrewer & 1.1-2   \\\\\n\t scales       & 1.1.1   \\\\\n\t tidyverse    & 1.3.1   \\\\\n\t boot         & 1.3-28  \\\\\n\t rpart        & 4.1-15  \\\\\n\\end{tabular}\n",
            "text/markdown": "\nA tibble: 36 × 2\n\n| Package &lt;chr&gt; | Version &lt;chr&gt; |\n|---|---|\n| caret        | 6.0-90   |\n| corrgram     | 1.14     |\n| corrplot     | 0.90     |\n| cowplot      | 1.1.1    |\n| dplyr        | 1.0.7    |\n| e1071        | 1.7-9    |\n| GGally       | 2.1.2    |\n| ggplot2      | 3.3.5    |\n| ggpubr       | 0.4.0    |\n| ggrepel      | 0.9.1    |\n| ggthemes     | 4.2.4    |\n| gridExtra    | 2.3      |\n| h2o          | 3.34.0.3 |\n| highcharter  | 0.8.2    |\n| janitor      | 2.1.0    |\n| lightgbm     | 3.3.1    |\n| plotly       | 4.10.0   |\n| plotrix      | 3.8-2    |\n| psych        | 2.1.9    |\n| randomForest | 4.6-14   |\n| repr         | 1.1.3    |\n| reshape2     | 1.4.4    |\n| rpart.plot   | 3.1.0    |\n| skimr        | 2.1.3    |\n| treemap      | 2.4-3    |\n| treemapify   | 2.5.5    |\n| viridis      | 0.6.2    |\n| xgboost      | 1.4.1.1  |\n| dplyr        | 1.0.7    |\n| ggplot2      | 3.3.5    |\n| magrittr     | 2.0.1    |\n| RColorBrewer | 1.1-2    |\n| scales       | 1.1.1    |\n| tidyverse    | 1.3.1    |\n| boot         | 1.3-28   |\n| rpart        | 4.1-15   |\n\n",
            "text/plain": [
              "   Package      Version \n",
              "1  caret        6.0-90  \n",
              "2  corrgram     1.14    \n",
              "3  corrplot     0.90    \n",
              "4  cowplot      1.1.1   \n",
              "5  dplyr        1.0.7   \n",
              "6  e1071        1.7-9   \n",
              "7  GGally       2.1.2   \n",
              "8  ggplot2      3.3.5   \n",
              "9  ggpubr       0.4.0   \n",
              "10 ggrepel      0.9.1   \n",
              "11 ggthemes     4.2.4   \n",
              "12 gridExtra    2.3     \n",
              "13 h2o          3.34.0.3\n",
              "14 highcharter  0.8.2   \n",
              "15 janitor      2.1.0   \n",
              "16 lightgbm     3.3.1   \n",
              "17 plotly       4.10.0  \n",
              "18 plotrix      3.8-2   \n",
              "19 psych        2.1.9   \n",
              "20 randomForest 4.6-14  \n",
              "21 repr         1.1.3   \n",
              "22 reshape2     1.4.4   \n",
              "23 rpart.plot   3.1.0   \n",
              "24 skimr        2.1.3   \n",
              "25 treemap      2.4-3   \n",
              "26 treemapify   2.5.5   \n",
              "27 viridis      0.6.2   \n",
              "28 xgboost      1.4.1.1 \n",
              "29 dplyr        1.0.7   \n",
              "30 ggplot2      3.3.5   \n",
              "31 magrittr     2.0.1   \n",
              "32 RColorBrewer 1.1-2   \n",
              "33 scales       1.1.1   \n",
              "34 tidyverse    1.3.1   \n",
              "35 boot         1.3-28  \n",
              "36 rpart        4.1-15  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35Mdqw5uUhYv"
      },
      "source": [
        "df <- read.csv('../input/real_estate_db.csv')\n",
        "\n",
        "head(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5RIGnI5UhYx"
      },
      "source": [
        "summary(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDyWumq_UhYx"
      },
      "source": [
        "numerics <- select_if(df, is.numeric)\n",
        "colnames(numerics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q30iH-cqUhYy"
      },
      "source": [
        "<h4> Types of Distributions </h4>\n",
        "<a id=\"mean_median\"></a>\n",
        "<ul> \n",
        "<li><b> Normal Distribution: </b> Also known as bell curve, is a distribution in which half of the data lies on the left side and the other half lies on the right side of the distribution. In this distribution the curve is symmetric and the mean, mode and median are all equal. </li>\n",
        "<li><b>Right Skewed Distribution:</b>has a long tail pointing to the <b>right</b>. This means that in our sample or population most of the data is concentrated to the left side of the distribution. <b> The rent mean </b> is in this case right-skewed which tells us that the average rent was mostly concentrated on the left side meaning that the majority of observations cannot afford a high rent.</li>\n",
        "<li><b>Left Skewed Distribution:</b> has a long tail pointing to the <b>left</b>. This means that in our sample or population most of the data is concentrated to the right side of the distribution. <b>Debt</b> is an example of a left skewed distribution meaning that most observations have a high concentration of debt, meaning most observations are in the right side. </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQbmZMBmUhYz"
      },
      "source": [
        "# What is the distribution of the family mean\n",
        "\n",
        "options(repr.plot.width=8, repr.plot.height=7)\n",
        "\n",
        "# numerics %>% filter(!is.na(family_mean)) %>% \n",
        "#   summarize(mean=mean(family_mean), sd=sd(family_mean))\n",
        "\n",
        "\n",
        "subset.rent <- numerics %>%\n",
        "  filter(!is.na(rent_mean))\n",
        "\n",
        "p1 <- ggplot(data=subset.rent, aes(x=rent_mean))+\n",
        "  geom_histogram(aes(y=..density..), bins = 40, fill=\"#81F781\")+\n",
        "  stat_function(fun=dnorm, color=\"black\",\n",
        "                args=list(mean=mean(subset.rent$rent_mean), \n",
        "                          sd=sd(subset.rent$rent_mean))) + theme_minimal() + \n",
        "theme(plot.title=element_text(hjust=0.5)) + labs(title=\"Right Skewed Distribution\", \n",
        "                                                x=\"Rent Mean\", y=\"Probability\")\n",
        "\n",
        "\n",
        "subset.female <- numerics %>%\n",
        "  filter(!is.na(female_age_mean))\n",
        "\n",
        "\n",
        "p2 <- ggplot(data=subset.female, aes(x=female_age_mean))+\n",
        "  geom_histogram(aes(y=..density..), bins = 40, fill=\"#FAAC58\")+\n",
        "  stat_function(fun=dnorm, color=\"black\",\n",
        "                args=list(mean=mean(subset.female$female_age_mean), \n",
        "                          sd=sd(subset.female$female_age_mean))) + theme_minimal() + \n",
        "theme(plot.title=element_text(hjust=0.5)) + labs(title=\"Normal Distribution\", \n",
        "                                                x=\"Female Age Mean\", y=\"Probability\")\n",
        "\n",
        "\n",
        "subset.debt <- numerics %>%\n",
        "  filter(!is.na(debt))\n",
        "\n",
        "\n",
        "p3 <- ggplot(data=subset.debt, aes(x=debt))+\n",
        "  geom_histogram(aes(y=..density..), bins = 40, fill=\"#FA5858\")+\n",
        "  stat_function(fun=dnorm, color=\"black\",\n",
        "                args=list(mean=mean(subset.debt$debt), \n",
        "                          sd=sd(subset.debt$debt))) + theme_minimal() + \n",
        "theme(plot.title=element_text(hjust=0.5)) + labs(title=\"Left Skewed Distribution\", \n",
        "                                                x=\"Debt\", y=\"Probability\")\n",
        "\n",
        "plot_grid(p1, p2, p3, align='h', nrow=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8Au9LHHUhYz"
      },
      "source": [
        "# Summary Statistics\n",
        "cols <- numerics %>% select(debt, rent_mean, female_age_mean) %>% \n",
        "filter(!is.na(debt), !is.na(rent_mean), !is.na(female_age_mean))\n",
        "\n",
        "do.call(cbind, lapply(cols, summary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktT5ubR1UhY0"
      },
      "source": [
        "options(repr.plot.width=8, repr.plot.height=4)\n",
        "# windows(height = 7, width = 3.5)\n",
        "# Lines: Mean is the blue line and Median the green line\n",
        "\n",
        "# First Subplot\n",
        "p4 <- hist(subset.rent$rent_mean, col=\"#F78181\", xlab=\"Rent\", main=\"Distribution of Rent\")\n",
        "abline(v = mean(subset.rent$rent_mean), col = \"blue\", lwd = 2, lty=\"dashed\")\n",
        "abline(v = median(subset.rent$rent_mean), col = \"green\", lwd = 2, lty=\"dashed\")\n",
        "legend(x = c(4000, 3200), y = c(8000, 5500), legend=c(\"Mean\", \"Median\"), col=c(\"blue\",\"green\"), cex=0.7, \n",
        "      lty=\"dashed\", lwd=1, y.intersp = 3.8, x.intersp=3.5, xjust=-1.8)\n",
        "\n",
        "\n",
        "# Second Subplot\n",
        "p5 <- hist(subset.female$female_age_mean, col=\"#F78181\", xlab=\"Age\", main=\"Distribution of Female Age\")\n",
        "abline(v = mean(subset.female$female_age_mean), col = \"blue\", lwd = 2, lty=\"dashed\")\n",
        "abline(v = median(subset.female$female_age_mean), col = \"green\", lwd = 2, lty=\"dashed\")\n",
        "legend(x = c(78, 95), y = c(12000, 8000), legend=c(\"Mean\", \"Median\"), col=c(\"blue\",\"green\"), cex=0.7, \n",
        "      lty=\"dashed\", lwd=1, y.intersp = 3.8, x.intersp=3.5, xjust=-1.8)\n",
        "\n",
        "# Third Subplot\n",
        "p6 <- hist(subset.debt$debt, col=\"#F78181\", xlab=\"Debt\", main=\"Distribution of Debt\")\n",
        "abline(v = mean(subset.debt$debt), col = \"blue\", lwd = 2, lty=\"dashed\")\n",
        "abline(v = median(subset.debt$debt), col = \"green\", lwd = 2, lty=\"dashed\")\n",
        "legend(x = c(0.85, 1), y = c(5000, 3500), legend=c(\"Mean\", \"Median\"), col=c(\"blue\",\"green\"), cex=0.8, \n",
        "      lty=\"dashed\", lwd=1, y.intersp = 2, x.intersp=0.7, xjust=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3__3Old-UhY1"
      },
      "source": [
        "<h4> Other Statistical Measures: </h4>\n",
        "<ul>\n",
        "<li><b>Variance:</b> This is an indicator of how spread our data is spread out. The smallest variabilitiy there could be is 0 while the biggest is infinite. Variance is expressed as: <br> $\\sigma^2 = \\frac{\\sum\\limits_{i=1}^N (X -\\mu)^2}{N}$ </li><br>\n",
        "<li><b>Standard Deviation:</b> The standard deviation is just the square root of our variance and it tells us how far our data is spread from the mean. Standard deviation is expressed as: <br>\n",
        "$s = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\overline{x})^2}$</li><br>\n",
        "<li><b>1st Quartile</b>: This is comprised of the lowest 25% of numbers in our distribution.  </li>\n",
        "<li><b>2nd Quartile (Q2)</b>: Comprised of 50% of lowest numbers up to the <b>median.</b> </li>\n",
        "<li><b>3rd Quartile (Q3)</b>: Comprised of 75% of lowest numbers. </li>\n",
        "<li><b> Interquartile Range (IQR)</b>: This helps us detect where most of the data lies. IQR is expressed as: <br>\n",
        "IQR = $Q_1 - Q_3$  <br>\n",
        "It is preferred to use IQR instead of the mean or median when trying to find out where most of the data lies.</li>\n",
        "\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01YuypLvUhY1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zxQVjwpUhY1"
      },
      "source": [
        "# We will use the male population now\n",
        "stat_rent <- numerics %>% filter(!is.na(rent_mean)) %>%\n",
        "  summarise(mu = mean(rent_mean), rent_med = median(rent_mean), \n",
        "            std = sd(rent_mean), \n",
        "            rent_min = min(rent_mean), rent_max = max(rent_mean),\n",
        "            rent_q1 = quantile(rent_mean, 0.25),  # first quartile, 25th percentile\n",
        "            rent_q3 = quantile(rent_mean, 0.75),# third quartile, 75th percentile\n",
        "           rent_iqr=rent_q3 - rent_q1)  # Interquartile Range\n",
        "\n",
        "stat_fage <- numerics %>% filter(!is.na(female_age_mean)) %>%\n",
        "  summarise(mu = mean(female_age_mean), fage_med = median(female_age_mean), \n",
        "            std = sd(female_age_mean),\n",
        "            fage_min = min(female_age_mean), fage_max = max(female_age_mean),\n",
        "            fage_q1 = quantile(female_age_mean, 0.25),  # first quartile, 25th percentile\n",
        "            fage_q3 = quantile(female_age_mean, 0.75), # third quartile, 75th percentile\n",
        "           fage_iqr=fage_q3 - fage_q1) # Interquartile Range\n",
        "\n",
        "\n",
        "stat_debt <- numerics %>% filter(!is.na(debt)) %>%\n",
        "  summarise(mu = mean(debt), debt_med = median(debt), \n",
        "            std = sd(debt),\n",
        "            debt_min = min(debt), debt_max = max(debt),\n",
        "            debt_q1 = quantile(debt, 0.25),  # first quartile, 25th percentile\n",
        "            debt_q3 = quantile(debt, 0.75), # third quartile, 75th percentile\n",
        "           debt_iqr=debt_q3 - debt_q1)  # Interquartile Range\n",
        "\n",
        "print(\"Rent Mean Statistics\")\n",
        "print(\"---------------------\")\n",
        "kable(stat_rent)\n",
        "print(\"Female Age Mean Statistics\")\n",
        "print(\"---------------------------\")\n",
        "kable(stat_fage)\n",
        "print(\"Debt Statistics\")\n",
        "print(\"---------------\")\n",
        "kable(stat_debt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSobBYLVUhY2"
      },
      "source": [
        "<h4> Boxplots and Suspected Outliers: </h4>\n",
        "<a id=\"boxplots\"></a>\n",
        "\n",
        "<img src=\"http://visualoop.com/media/2015/04/box_plot_anatomy.png\">\n",
        "\n",
        "\n",
        "\n",
        "<h4> A Word Regarding Outliers: </h4>\n",
        "I just wanted to add in this section that outliers should be carefully analyzed and although there are common rules such as that in a \"normal distribution\" any value beyond three standard deviations should be consider an outlier. Eventhough, there is a small probability that a value in a normal distribution is 3 standard deviations away from the mean, we should carefully analyze as of why is this the case. It could be that in data was mistyped which will weakened the theory that a specific observation is an outlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS_rZGeUUhY2"
      },
      "source": [
        "# Use boxplots to explain better the concepts of quartiles\n",
        "\n",
        "# We will use type of place\n",
        "t.place <- df %>% select(rent_mean, type) %>% \n",
        "filter(!is.na(rent_mean), !is.na(type)) %>%\n",
        "ggplot(aes(x=type, y=rent_mean)) + geom_boxplot(fill=\"white\", colour=\"black\", \n",
        "                                                outlier.colour = \"red\", outlier.shape = 1) + \n",
        "theme_minimal() + theme(plot.title=element_text(hjust=0.5)) + coord_flip() + \n",
        "labs(title=\"Distribution of Average Rent by Type of Place\", x=\"Type\", y=\"Average Rent\")\n",
        "\n",
        "t.place + scale_fill_manual(values=c(\"#999999\", \"#E69F00\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSmsDbvFUhY2"
      },
      "source": [
        "<h4> Understanding Q-Plots </h4>\n",
        "<a id=\"qplots\"></a>\n",
        "<ul>\n",
        "<li><b> Right Skewed Qplot: </b> When the distribution is right skewed, the observations tend to go above the red line indicating that the distribution is right-skewed.\n",
        "<li><b> Normal Distribution Qplot: </b> Although some observations are not on the line, most of the observations are on the line which indicates that the distribution is mostly normal. </li>\n",
        "<li><b>Left Skewed Qplot: </b> Although this distribution is not strongly left skewed, we can see that most observations fall below the red line, indicating that the distribution is left-skewed. </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHGVqCp9UhY2"
      },
      "source": [
        "# Right Skew\n",
        "options(repr.plot.width=10, repr.plot.height=8)\n",
        "par(mfrow=c(3,2)) \n",
        "# First subplot (Right Skewed)\n",
        "hist(subset.rent$rent_mean, main=\"Right Skewed Distribution\", xlab=\"Average Rent\", col=\"#81F781\")\n",
        "qqnorm(subset.rent$rent_mean, col=\"blue\")\n",
        "qqline(subset.rent$rent_mean, col=\"red\")\n",
        "\n",
        "# Second subplot (Normal Distribution)\n",
        "hist(subset.female$female_age_mean, main=\"Normal Distribution\", xlab=\"Average Age\", col=\"#FAAC58\")\n",
        "qqnorm(subset.female$female_age_mean, col=\"blue\")\n",
        "qqline(subset.female$female_age_mean, col=\"red\")\n",
        "\n",
        "# Third Subplot\n",
        "hist(subset.debt$debt, main=\"Left Skewed Distribution\", xlab=\"Debt\", col=\"#FA5858\")\n",
        "qqnorm(subset.debt$debt, col=\"blue\")\n",
        "qqline(subset.debt$debt, col=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17JceWuDUhY3"
      },
      "source": [
        "<h3>Using Natural Logarithms to Create a Normal Distributions: </h3> \n",
        "Although sometimes using natural logarithms does not necesarily impact the observations to form a normal distribution (left-skewed example), most of the times it gives us an approximate normal distribution just like in the right-skewed example. <br>\n",
        "\n",
        "<b> Why would we want a normal distribution?</b><br>\n",
        "Although there are many ways to deal with skewedness, most of the statistical techniques assume that the distribution is \"normal\". We will further explain, which statistical techniques are those. Statistical tests such as z, t and F-tests, assume that the mean is \"normally\" distributed. Moreover, it is somewhat simpler to calculate probabilities and to calculate confidence intervals assuming the distribution meets the <b> Central Limit Theorem (CLT) </b> conditions. \n",
        "\n",
        "\n",
        "<b> More on Central Limit Theorem Conditions: </b><br>\n",
        "<a href=\"http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Probability/BS704_Probability12.html\"> More on Central Limit Theorem </a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sy_dwANUhY3"
      },
      "source": [
        "# Right Skew\n",
        "options(repr.plot.width=10, repr.plot.height=8)\n",
        "par(mfrow=c(3,2)) \n",
        "# First subplot (Right Skewed)\n",
        "hist(log1p(subset.rent$rent_mean), main=\"Right Skewed Distribution\", xlab=\"Average Rent\", col=\"#81F781\")\n",
        "qqnorm(log1p(subset.rent$rent_mean), col=\"blue\")\n",
        "qqline(log1p(subset.rent$rent_mean), col=\"red\")\n",
        "\n",
        "# Second subplot (Normal Distribution)\n",
        "hist(log1p(subset.female$female_age_mean), main=\"Normal Distribution\", xlab=\"Average Age\", col=\"#FAAC58\")\n",
        "qqnorm(log1p(subset.female$female_age_mean), col=\"blue\")\n",
        "qqline(log1p(subset.female$female_age_mean), col=\"red\")\n",
        "\n",
        "# Third Subplot\n",
        "hist(log1p(subset.debt$debt), main=\"Left Skewed Distribution\", xlab=\"Debt\", col=\"#FA5858\")\n",
        "qqnorm(log1p(subset.debt$debt), col=\"blue\")\n",
        "qqline(log1p(subset.debt$debt), col=\"red\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCA21HYoUhY3"
      },
      "source": [
        "### Visualizing Confidence Intervals with ggplot:\n",
        "With Confidence intervals we make sure how confident we are of what is the true population average.<b> The wider the error bars, the less certain of what the true mean is. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_AFhPyoUhY4"
      },
      "source": [
        "options(repr.plot.width=8, repr.plot.height=6)\n",
        "subset.female <- df %>% filter(!is.na(female_age_mean))\n",
        "\n",
        "ggplot(data=subset.female, aes(x=type, y=female_age_mean)) + stat_summary(fun.data=mean_cl_normal, color=\"red\") + theme_minimal() + \n",
        "theme(plot.title=element_text(hjust=0.5)) + labs(title=\"CI for Average Female Age by Zone Type\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB6F1PdjUhY4"
      },
      "source": [
        "# Function to find the female range\n",
        "age_range <- function(x) {\n",
        "  # Change x below to return the instructed values\n",
        "  data.frame(ymin = min(x), # Min\n",
        "             ymax = max(x)) # Max\n",
        "}\n",
        "\n",
        "age_range(subset.female$female_age_mean)\n",
        "\n",
        "\n",
        "# Finding the Interquartile Range\n",
        "# Function to Custom function\n",
        "IQR <- function(x) {\n",
        "  # Change x below to return the instructed values\n",
        "  data.frame(median = median(x), # Median\n",
        "             first_quartile = quantile(x, 0.25), # 1st quartile\n",
        "             third_quartile = quantile(x, 0.75),\n",
        "            interquartile_range=(quantile(x, 0.75) - quantile(x, 0.25))) # 3rd quartile\n",
        "}\n",
        "\n",
        "IQR(subset.female$female_age_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp1RnC0dUhY4"
      },
      "source": [
        "<h3> Inference Statistics: </h3>\n",
        "<a id=\"hypothesis_testing\"></a>\n",
        "In this section we will talk about the importance of confidence intervals and how can we find the confidence interval of a distribution. Moreover, we will go briefly into the topics of hypothesis testing and explain why it is important to know these concepts before even trying to answer the question to our main problem.\n",
        "\n",
        "\n",
        "<h4>Hypothesis Testing (Guilty or not Guilty?) </h4>\n",
        "Imagine a scenario where an individual is in a trial for commiting a murder in the United States. As far as we know, when an individual is consider <b>\"innocent\"</b> until proven otherwise. Through this brief example I would like to introduce the concept of <b>Hypothesis Testing</b>. There are two types of hypothesis the <b> Null Hypothesis </b> and the <b> Alternative Hypothesis.</b><br>\n",
        "\n",
        "\n",
        "<ul> \n",
        "<li> <b> Null Hypothesis ($H_0$): </b> This is the \"status quo\", in our example the individual who is in trial is <b>innocent</b>. When we want to compare means of two variables let's say the average income of male and female the Null hypothesis in this case will be that there is \"no difference\". </li>\n",
        "<li> <b> Alternative Hypothesis ($H_A$): </b> This is going against what the Null Hypothesis was stating. An individual who went to trial is <b>guilty.</b>In our average income by gender example, the average income of males does not equal the average income of females. </li>\n",
        "\n",
        "</ul>\n",
        "\n",
        "<b> Null Hypothesis (Average Income Example): </b><br>\n",
        "$Aincome_M = Aincome_F$ <br><br>\n",
        "\n",
        "<b> Alternative Hypothesis (Average Income Example): </b><br>\n",
        "$Aincome_M \\ne Aincome_F$\n",
        "\n",
        "\n",
        "\n",
        "<h4> Confidence Intervals and P-values: </h4> \n",
        "\n",
        "<img src=\"https://www.researchgate.net/profile/Vladimir_Kekez/publication/271846185/figure/fig6/AS:295099222249473@1447368545063/Visual-interpretation-of-distribution-of-Significance-Level-p-values-and-z-score-in.png\">\n",
        "<b>Confidence Intervals (CI)</b> are how certain a specific value will lie between two specific points. The most common types of confidence intervals are the 90%, 95% and 99% conficence intervals although the 95% is the one that is most commonly used and is the one we will use in this example.<br>\n",
        "\n",
        "<b> P-value:</b> is the probability of ocurrence of a given event. Assuming a confidence interval is 95%, if p-value < $\\alpha$, then we reject the Null Hypothesis in favor of the Alternative Hypothesis. <br>\n",
        "\n",
        "<b> Significance Level:</b> is the probability of rejecting the Null Hypothesis (also denoted as alpha or $\\alpha$.\n",
        "\n",
        "<b> Finding the Confidence Interval for the Population Mean: </b><br><br>\n",
        "\n",
        "$\\overline{x}\\pm z^* s \\frac{s}{\\sqrt{N-1}}$<br>\n",
        "\n",
        "$\\overline{x}$ = Sample Mean <br>\n",
        "z = z-score <br>\n",
        "s = Standard Error <br>\n",
        "N = Sample size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyrZQUpuUhY5"
      },
      "source": [
        "# Let's calculate the 95% Confidence Level of Male_Age_Mean (Normal Distribution)\n",
        "# Cut the x-axis\n",
        "options(repr.plot.width=6, repr.plot.height=3)\n",
        "\n",
        "# First let's see if Male_Age_Mean follows a normal distribution one of the criterias\n",
        "f.age <- numerics %>% select(female_age_mean) %>% filter(!is.na(female_age_mean)) %>%\n",
        "ggplot(aes(x=female_age_mean, y=..density..)) + geom_histogram(bins = 120, fill=\"red\") + \n",
        "theme_bw() + scale_x_continuous(breaks = seq(20, 80, 10),\n",
        "                               limits=c(20, 80)) + labs(title=\"Distribution of Age from Females\") + \n",
        "theme(plot.title=element_text(hjust=0.5))\n",
        "\n",
        "f.age"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noDAjP_lUhY5"
      },
      "source": [
        "# Technique 1: Manually using the statistical measures.\n",
        "\n",
        "# Sample size\n",
        "n <- numerics %>% filter(!is.na(female_age_mean)) %>% nrow()\n",
        "print(paste0(\"Number of rows after filtering Null values \", n))\n",
        "# standard deviation\n",
        "std <- numerics %>% filter(!is.na(female_age_mean)) %>% summarise(std=sd(female_age_mean))\n",
        "# Sample mean\n",
        "x_bar <- numerics %>% filter(!is.na(female_age_mean)) %>% summarise(avg=mean(female_age_mean))\n",
        "\n",
        "# standard error 95% confidence level\n",
        "# We used a negative sign to turn it positive\n",
        "serror <- -qnorm(0.025)*std/sqrt(n)\n",
        "\n",
        "lower_interval <- x_bar - serror\n",
        "upper_interval <- x_bar + serror\n",
        "\n",
        "print(paste0(\"The lower interval is \", round(lower_interval,2), \"  Upper interval is: \", round(upper_interval, 2)))\n",
        "\n",
        "\n",
        "f.age <- numerics %>% filter(!is.na(female_age_mean))\n",
        "\n",
        "# Technique #2 using rcompanion library (Not able to use on Kaggle but it is simpler to use)\n",
        "# groupwiseMean(female_age_mean ~ 1, \n",
        "#               data   = f.age, \n",
        "#               conf   = 0.95, \n",
        "#               digits = 7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBzQXWebUhY5"
      },
      "source": [
        "<b> So how do we interpret this confidence level example? </b><br>\n",
        "<a id=\"confidence_intervals\"></a>\n",
        "95% of random samples from a sample size of 38,728 (female_age_mean without Nulls) of female Americans will yield confidence intervals that capture the true population age mean of females. (40.2 - 40.32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBoD598PUhY5"
      },
      "source": [
        "# Manually added rep_sample_n function from statsr library\n",
        "rep_sample_n <- function(tbl, size, replace = FALSE, reps = 1)\n",
        "{\n",
        "    n <- nrow(tbl)\n",
        "    i <- unlist(replicate(reps, sample.int(n, size, replace = replace), simplify = FALSE))\n",
        "\n",
        "    rep_tbl <- cbind(replicate = rep(1:reps,rep(size,reps)), tbl[i, , drop=FALSE])\n",
        "\n",
        "    dplyr::group_by(rep_tbl, replicate)\n",
        "}\n",
        "\n",
        "\n",
        "# As we increase sample size the greater the accuracy\n",
        "n <- 50\n",
        "ci_95 <- qnorm(0.975)\n",
        "\n",
        "\n",
        "ci <- f.age %>%\n",
        "  rep_sample_n(size = n, reps = 50, replace = TRUE) %>%\n",
        "  summarise(lower = mean(female_age_mean) - ci_95 * (sd(female_age_mean) / sqrt(n)),\n",
        "            upper = mean(female_age_mean) + ci_95 * (sd(female_age_mean) / sqrt(n)))\n",
        "\n",
        "\n",
        "# Let's see how many times is the actual mean between the lower and upper bounds\n",
        "f.avg <- f.age %>% summarise(avg=mean(female_age_mean))\n",
        "\n",
        "\n",
        "ci <- ci %>%\n",
        "  mutate(capturing_avg = ifelse(lower < f.avg$avg & upper > f.avg$avg, \"In Between\", \"Out of Bounds\"))\n",
        "\n",
        "score <- length(which(ci$capturing_avg == \"In Between\")) / nrow(ci) * 100\n",
        "\n",
        "\n",
        "print(paste0(\"The percentage in which the true average is 'in between': \", score, \"%\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMAOIS2zUhY5"
      },
      "source": [
        "# We need the mean, standard deviation, sample mean, sample size\n",
        "# To make sample mean and standard deviation get the information from the same sample.\n",
        "set.seed(42)\n",
        "mu <- mean(f.age$female_age_mean)\n",
        "n <- 50 # Sample size\n",
        "x_bar <- mean(sample(f.age$female_age_mean, 50))\n",
        "std_bar <- sd(sample(f.age$female_age_mean, 50))\n",
        "standard_error <- qnorm(0.025)*std_bar/sqrt(n) # 95% confidence level\n",
        "\n",
        "# The Z-score\n",
        "z_score <- (x_bar - mu)/standard_error\n",
        "\n",
        "print(paste0(\"Z_score is: \", round(z_score, 2)))\n",
        "\n",
        "z <- (3.2 - 3) / 0.246\n",
        "\n",
        "# p-value for two sides\n",
        "p_val <- 2*pnorm(-abs(z_score))\n",
        "print(paste0(\"Two sided p-value is:  \", round(p_val,2)))\n",
        "\n",
        "# p-value for one side\n",
        "ones_pval <- p_val / 2\n",
        "print(paste0(\"One sided p-value is:  \", round(ones_pval,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJbaNeI-UhY5"
      },
      "source": [
        "<a id=\"p_val\"></a>\n",
        "<b> In this case, since p-value is > than $\\alpha$ we do not reject $H_0$</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGDeMRRPUhY6"
      },
      "source": [
        "<h4>Contingency Tables: </h4>\n",
        "<a id=\"contingency\"></a>\n",
        "The main goal of contingency tables is to summarize the relationship between two categorical variables. In this example, we summarize the relationship between state and type.\n",
        "\n",
        "<h4> Chi-Squared Test of Independence </h4>\n",
        "<a id=\"chi_s\"> </a>\n",
        "<ul>\n",
        "    <li><b>Null Hypothesis($H_0$):</b> There is no association between the two variables. </li>\n",
        "    <li><b>Alternative Hypothesis ($H_A$):</b> There is an association between the two variables and hence, the variables are dependent. </li>\n",
        "</ul>\n",
        "\n",
        "<b> Note:</b> I will go later more in-depth into the test of independency and what does it mean however, I just wanted to show a simple way to make sure that independency exists between two variables in order to meet one of the conditions of the <b> Central Limit Theorem.</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUiOD2H4UhY6"
      },
      "source": [
        "categoricals <- select_if(df, is.factor)\n",
        "\n",
        "colnames(categoricals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdh3MYURUhY6"
      },
      "source": [
        "mytable <- table(categoricals$type, categoricals$state)\n",
        "summary(mytable) # chi-square test of indepedence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnHw0X6GUhY6"
      },
      "source": [
        "<b>In later updates I will go more in depth into the chi squared test of independence. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfAlOEzjUhY6"
      },
      "source": [
        "cont.table <- categoricals %>% select(state, type) %>% table() %>% prop.table() %>% `*` (100) %>% round(2)\n",
        "\n",
        "cont.table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOcT3QaHUhY6"
      },
      "source": [
        "<ul> \n",
        "    <li><b> First Row:</b> Number of Observations.  </li>\n",
        "    <li><b>Second Row:</b> Chi Square Contribution. </li>\n",
        "    <li><b> Third Row:</b>Total Percentage per Row </li>\n",
        "    <li><b>Fourth Row: </b> Total Percentage per Column </li>\n",
        "    <li><b>Fifth Row:  </b>Total Percentage of the Table. </li>\n",
        "    </ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhAYTqBBUhY6"
      },
      "source": [
        "# Contingency Table with CrossTable\n",
        "library(descr)\n",
        "# There might be a problem with the NAS\n",
        "\n",
        "type_state <- df %>% filter(!is.na(type), !is.na(state)) \n",
        "\n",
        "CrossTable(type_state$state, type_state$type, prop.c=TRUE, prop.chisq=TRUE, prop.t=TRUE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQeOEmG1UhY6"
      },
      "source": [
        "<h4> T-Distribution </h4>\n",
        "<a id=\"t_distribution\"></a>\n",
        "<img src=\"https://i2.wp.com/www.real-statistics.com/wp-content/uploads/2012/11/t-distribution-chart.png?resize=439%2C264\">\n",
        "The t-distribution is a distribution that is only used for small samples. The first question I had when dealing with this types of distribution is why we need a t-distribution when we receive daily tons of data making it impossible to have a small sample. Well, t-distributions are more often used when <b>conducting an experiment</b> which usually have smaller samples. <br><br>\n",
        "\n",
        "<b>Summary of t-Distribution: </b>\n",
        "<ul>\n",
        "    <li><b>Sample Size: </b> The sample size must be smaller than 30 in order to be considered for a t-distribution. </li>\n",
        "    <li><b>Degrees of freedom:</b> As the sample size gets closer to 30, the t-distribution will look exactly like a normal distribution. Also, degrees of freedom determines the thickness of the tail. </li>\n",
        "    <li><b>T-score: </b> To calculate the t-score we use the following formula, $(\\overline{x} - Null) / s$ where s is the standard error and Null the Null Hypothesis.</li>\n",
        "    \n",
        "</ul>\n",
        "\n",
        "\n",
        "<b> Excercise 1: Let's find the 95% Confidence Interval of a sample for the rent_mean in the state of New York.</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsBlUYMUUhY6"
      },
      "source": [
        "# Doing inference with the t-distribution Course 2 Week 3\n",
        "\n",
        "\n",
        "\n",
        "two_states <- df %>% select(state, rent_mean) %>% filter(state == \"California\"| state == \"New York\") %>%\n",
        "filter(!is.na(rent_mean))\n",
        "\n",
        "# On one sample degrees of freedom is (n - 1)\n",
        "set.seed(42)\n",
        "sample_twostates <- sample_n(two_states, 22)\n",
        "\n",
        "# Finding the critical t-score (We always use a positive critical score.)\n",
        "# qt(0.025, df=23)\n",
        "\n",
        "\n",
        "# Let's estimate the rent average for the state of New York using a 95% confidence level\n",
        "ny_samp <- sample_twostates %>% filter(state == \"New York\")\n",
        "\n",
        "# sample size \n",
        "n <- ny_samp %>% nrow()\n",
        "# Sample mean\n",
        "x_bar <- ny_samp %>% summarise(avg=mean(rent_mean))\n",
        "# t-score (df = n - 1)\n",
        "t_score <- abs(qt(0.025, df=11))\n",
        "\n",
        "std_ny <- ny_samp %>% summarise(std=sd(rent_mean))\n",
        "\n",
        "# Find the 95% confidence interval\n",
        "upper_bound <- x_bar + t_score * (std_ny / sqrt(n))\n",
        "lower_bound <- x_bar - t_score * (std_ny / sqrt(n))\n",
        "\n",
        "# We are 95% confident that the  rent mean for the city of new york lies between 934 - 1417"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWhftn7dUhY7"
      },
      "source": [
        "<b> Excercise 2: Assume Mu = 1000 for the rent of New York, let's find the p-value to see if there is sufficient evidence that we could reject $H_0$ in favor of $H_A$, remember if the p-value is less than 0.05 significance level then we reject the Null in favor of the alternative. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs7DAEpdUhY7"
      },
      "source": [
        "# Let's find the p-value let's assume that the Null is that the Mu = 1000\n",
        "standard_error <- std_ny / sqrt(n)\n",
        "\n",
        "\n",
        "# Let's find the t-score\n",
        "mu <- 1000\n",
        "t_score <- (x_bar -  mu) / standard_error\n",
        "\n",
        "\n",
        "\n",
        "# We have a t-score of 1.605\n",
        "# degrees of freedom = 11\n",
        "\n",
        "# Let's find the p-value\n",
        "# We need the two tails \n",
        "2 * pt(1.605, df=11, lower.tail=FALSE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCdNXOjJUhY7"
      },
      "source": [
        "Since our p-value is greater than 0.05 we go in favor of the <b> Null Hypothesis </b> , meaning that there is not sufficient evidence that the average rent in New York is something different than 1000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvScJhPiUhY7"
      },
      "source": [
        "<h4> Estimating the Difference between independent Means from two categorical variables</h4>\n",
        "<a id=\"two_independent\"></a>\n",
        "\n",
        "<ul>\n",
        "    <li><b>Degrees of Freedom: </b> df = $Min(n_1 - n_2)$ </li>\n",
        "    <li><b> Point of Estimates (Sample Mean): </b>   ($\\overline{x_1} {-} \\overline{x_2}$) </li>\n",
        "    <li><b> Standard Error of difference between two independent means:</b> $SE(_\\overline{x_1}-_\\overline{x_2})$ = $\\sqrt{SE_1^2} + \\sqrt{SE_2^2}$ <br> where $SE_1$ = $\\frac{S_1}{\\sqrt{n_1}}$ and $SE_2$ = $\\frac{S_2}{\\sqrt{n_2}}$</li>\n",
        "    <li><b>Difference between independent means formula:</b> SE = $(\\overline{x_1} - \\overline{x_2})\\pm t^*_{df} SE_{\\overline{x_1} - \\overline{x_2}}$ </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmAx7xcBUhY7"
      },
      "source": [
        "# Boxplots of means of florida and texas\n",
        "options(repr.plot.width=8, repr.plot.height=5)\n",
        "\n",
        "\n",
        "south_states <- df %>% select(state, rent_mean) %>% filter(state == \"Texas\" | state == \"Florida\") %>%\n",
        "ggplot(aes(x=state, y=rent_mean, fill=state)) + geom_boxplot() + \n",
        "stat_summary(fun.y=mean, colour=\"orange\", geom=\"point\", size=1) + \n",
        "theme_minimal() + \n",
        "theme(plot.title=element_text(hjust=0.5, size=10)) + \n",
        "labs(title=\"Difference Between Two Independent Means\", y=\"Rent Mean\", x=\"States\") + \n",
        "scale_fill_brewer(palette=\"Set3\")\n",
        "\n",
        "south_states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khZ5LwF_UhY7"
      },
      "source": [
        "set.seed(42)\n",
        "\n",
        "# Same sample size between the two categories (n = 24)\n",
        "two_states <- df %>% select(state, rent_mean) %>% filter(!is.na(rent_mean)) %>% \n",
        "filter(state == \"Florida\" | state == \"Texas\") %>% group_by(state) %>%\n",
        "do(sample_n(., size = 24))\n",
        "\n",
        "\n",
        "small_sample <- two_states %>% ungroup() \n",
        "\n",
        "\n",
        "# # Sample sizes \n",
        "n_1 <- small_sample %>% filter(state == \"Texas\") %>% nrow()\n",
        "n_2 <- small_sample %>% filter(state == \"Florida\") %>% nrow()\n",
        "\n",
        "# Sample mean for each state\n",
        "xbar_tex <- small_sample %>% filter(state == \"Texas\") %>% summarise(avg=mean(rent_mean))\n",
        "xbar_flo <- small_sample %>% filter(state == \"Florida\") %>% summarise(avg=mean(rent_mean))\n",
        "\n",
        "# Standard deviation\n",
        "std_tex <- small_sample %>% filter(state == \"Texas\") %>% summarise(std=sd(rent_mean))\n",
        "std_flo <- small_sample %>% filter(state == \"Florida\") %>% summarise(std=sd(rent_mean))\n",
        "\n",
        "# Degrees of freedom\n",
        "deg_f <- min(n_1 - 1, n_2 - 1)\n",
        "\n",
        "# T-score\n",
        "t_score <- abs(qt(0.025, df=deg_f))\n",
        "\n",
        "# Standard Error\n",
        "s1 <- std_tex/sqrt(n_1)\n",
        "s2 <- std_flo/sqrt(n_2)\n",
        "\n",
        "std_error <- sqrt(s1)^2 + sqrt(s2) ^ 2\n",
        "\n",
        "# Estimate the difference in rent between Texas and Florida\n",
        "upper_bound <- xbar_tex - xbar_flo + (t_score * std_error)\n",
        "lower_bound <- xbar_tex - xbar_flo - (t_score * std_error)\n",
        "\n",
        "\n",
        "# We are 95% confident that the difference in mean between these two variables range \n",
        "# between -492.34 - 150.55"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYuNQ2xgUhY7"
      },
      "source": [
        "Time for some <b> Hypothesis Testing </b>. Remember if the p-value is < 0.05 of our significance level then we reject the null hypothesis in favor of the alternative hypothesis. <br>\n",
        "\n",
        "<ul>\n",
        "    <li><b>Null Hypothesis ($H_0$)</b>: There is no difference between average rents in the states of Florida and Texas or $H_{tex} - H_{flo} = 0$ </li>\n",
        "    <li><b>Alternative Hypothesis ($H_A$)</b>: There is a difference between the average rents in the states of Florida and Texas or $H_{tex} - H_{flo} \\neq 0$ </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHAflJAEUhY7"
      },
      "source": [
        "# (Point of estimate - Null) / Standard Error\n",
        "p_estimate <- (xbar_tex - xbar_flo)\n",
        "\n",
        "t_score <- abs((p_estimate - 0)/std_error)\n",
        "\n",
        "t_score <- as.numeric(t_score)\n",
        "\n",
        "# p-value (> 0.05)\n",
        "# Degrees of freedom is n-1 or 24-1\n",
        "p_value <- 2 * pt(t_score, df=23, lower.tail=FALSE)\n",
        "p_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwzRrmzvUhY8"
      },
      "source": [
        "<b>The p-value indicates that there is no significance evidence that indicates that there is a difference between the average rent between the states of Texas and Florida. </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omm5sA9WUhY8"
      },
      "source": [
        "<h4> Comparing Different Means from Categorical Variables: </h4>\n",
        "<a id=\"anova\"></a>\n",
        "To compare more than two categorical variables we will need <b>F-Statistics</b> and <b> Analysis of Variance (ANOVA) </b><br>\n",
        "\n",
        "\n",
        "<b> Hypothesis Testing: </b>\n",
        "<ul>\n",
        "<li>$H_0$: The mean is the same across the 4 states mentioned below. </li>\n",
        "<li>$H_A$: At least one pair of mean are different from each other.</li>\n",
        "</ul>\n",
        "\n",
        "<b> F-Statistics: </b><br>\n",
        "$\\frac{Variability \\ between \\ groups}{Variability \\ within \\ groups}$<br>\n",
        "\n",
        "<ul> \n",
        "    <li><b> Between Group Variability:</b> Variability that comes within the class (Direct correlation with the states).</li>\n",
        "    <li> <b>Within Group Variability: </b> Variability that comes due to other factors. </li>\n",
        "    </ul>\n",
        "    \n",
        "    \n",
        "<ul>\n",
        "    <li><b>Sum of Squares:</b> Measures the total variability of our response variable (ex: Average Rent).\n",
        " $$SSG = \\sum_{i=1}^{n} n_j(y_i - \\overline{y})^2$$ where <b>$y_i$ </b>= Value of the response variable while $\\overline{y}$ = Grand mean of the response variable (Average rent per state) and $n_j$ = the number of observations in the group. </li>\n",
        "\n",
        " </ul>\n",
        "\n",
        "<b> Summary: </b><br>\n",
        "<ul>\n",
        "    <li><b>Sample Size: </b> A sample size of 250 observations is used in this example for each of the states (total of 1000 observations). </li>\n",
        "    <li><b>P-value: </b> P-value in this case is less that 0.05 which indicates that at least one pair of the states shows enough evidence that the means are different. </li>\n",
        "    <li><b>Adjusted P-Value: </b> The states that have the highest adjusted p-value are Texas and Florida which is not a surprise since these are the two states that have a similar average rent. </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD05UUAnUhY8"
      },
      "source": [
        "# A small summary of the average rent mean per state\n",
        "library(dplyr)\n",
        "\n",
        "all_avg <- df %>% select(state, rent_mean) %>% group_by(state) %>% filter(!is.na(rent_mean)) %>% \n",
        "filter(state == \"New York\" | state == \"California\"| state == \"Florida\" | state == \"Texas\") %>%\n",
        "summarise(avg=mean(rent_mean), Count=n(), std=sd(rent_mean))\n",
        "\n",
        "\n",
        "all_avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu0suNLWUhY8"
      },
      "source": [
        "# Avoid Randomness\n",
        "set.seed(42)\n",
        "\n",
        "# Sampling\n",
        "four_states <- df %>% select(state, rent_mean) %>% filter(!is.na(rent_mean)) %>% \n",
        "filter(state == \"New York\" | state == \"California\"| state == \"Florida\" | state == \"Texas\") %>%\n",
        "group_by(state) %>% do(sample_n(., size=250))\n",
        "\n",
        "ggplot(four_states, aes(x=state, y=rent_mean, fill=state)) + geom_boxplot() + \n",
        "stat_summary(fun.y=mean, colour=\"orange\", geom=\"point\", size=1) + \n",
        "theme_minimal() + theme(plot.title=element_text(hjust=0.5, size=12)) + \n",
        "labs(title=\"Difference in Independent Categorical Means \\n (Sample Size 250)\", x=\"States\", y=\"Average Rent\") + \n",
        "scale_fill_brewer(palette=\"Set3\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAFYorGaUhY8"
      },
      "source": [
        "# ANOVA Testing\n",
        "\n",
        "\n",
        "fours_sample <- four_states %>% ungroup() \n",
        "\n",
        "# Change to short abbreviations \n",
        "levels(fours_sample$state)[levels(fours_sample$state)==\"Texas\"] <- \"Tx\"\n",
        "levels(fours_sample$state)[levels(fours_sample$state)==\"Florida\"] <- \"Fl\"\n",
        "levels(fours_sample$state)[levels(fours_sample$state)==\"California\"] <- \"Ca\"\n",
        "levels(fours_sample$state)[levels(fours_sample$state)==\"New York\"] <- \"Ny\"\n",
        "\n",
        "\n",
        "aov_states <- aov(rent_mean ~ state, data=fours_sample)\n",
        "\n",
        "aov_states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic1P85sQUhY8"
      },
      "source": [
        "\n",
        "summary(aov_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoOKmxRrUhY8"
      },
      "source": [
        "<b> Expand the summary (p-value less than 0.05), evidence to believe that not all means are equal. </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjtefoqDUhY8"
      },
      "source": [
        "attributes(aov_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xAPX2IHUhY9"
      },
      "source": [
        "options(repr.plot.width=7, repr.plot.height=4)\n",
        "\n",
        "plot(aov_states$residuals, ylab=\"Residuals\", main=\"Residuals Plot\", col=\"red\", lwd = 0.5)\n",
        "abline(h=0,col=1, lty=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnxyOCHEUhY9"
      },
      "source": [
        "<b>Texas and Florida have the highest similarity in the average rent between states according to the adjusted p-value (the highest) </b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSuCmahlUhY9"
      },
      "source": [
        "TukeyHSD(aov_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KpR2rYtUhY9"
      },
      "source": [
        "plot(TukeyHSD(aov_states), las=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pFVhIq5UhY9"
      },
      "source": [
        "### Bootstrapping (Simulation Base-Method):\n",
        "<a id=\"bootstrapping\"></a>\n",
        "We make small samples from a big sample to make inference from the unknown population. Remember, the population is unknown, the dataset we have is based on samples rather than the whole US population. In this exaple, we will use as much as 1000 samples with the size of 750 observations from the big sample in order to infer what is the median of the average mortgage cost of the population. Something to mention, is that the random samples are done with replacement which means that after the first sample is taken in the second sample observations from the first sample could still be taken.\n",
        "\n",
        "\n",
        "### Key intakes from Bootstrapping:\n",
        "<ul>\n",
        "    <li>Treat the sample as the population (in this case our entire dataset is the population). </li>\n",
        "    <li>Bootstrapping can be used for many purposes but in this case we are using it to find the confidence intervals. </li>\n",
        "    <li> Bootstrapping is also used when we stack models together to make certain predictions.</li>\n",
        "    </ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy59bR1OUhY9"
      },
      "source": [
        "# Mortgage Costs Right Skew\n",
        "subset_mortgage <- df %>% select(hc_mortgage_mean) %>% filter(!is.na(hc_mortgage_mean))\n",
        "\n",
        "\n",
        "ggplot(data=subset_mortgage, aes(x=hc_mortgage_mean)) + geom_histogram(aes(y=..density..), bins=40, fill=\"#800000\") + \n",
        "stat_function(fun=dnorm, color=\"black\",\n",
        "                args=list(mean=mean(subset_mortgage$hc_mortgage_mean), \n",
        "                          sd=sd(subset_mortgage$hc_mortgage_mean))) + theme_minimal() + \n",
        "labs(title=\"Mortgage Cost (Right-Skewed)\") + theme(plot.title=element_text(hjust=0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEevAJA4UhY9"
      },
      "source": [
        "# Determine which variable we are going to do Bootstrappoing\n",
        "# Watch again the video of Coursera\n",
        "library(boot)\n",
        "\n",
        "# Function to take the median of each sample\n",
        "BootstrapMedian <- function(x=subset_mortgage$hc_mortgage_mean){\n",
        "    x.boot <- sample(x, size=length(1000), replace=T)\n",
        "    median(x.boot)\n",
        "}\n",
        "\n",
        "# median(subset_mortgage$hc_mortgage_mean)\n",
        "BootstrapMedian()\n",
        "sample_boost <- replicate(2000, BootstrapMedian())\n",
        "\n",
        "\n",
        "hist(sample_boost, col=\"#ff4848\", breaks = 25, main=\"Bootstrap Sample Distribution\")\n",
        "abline(v=median(subset_mortgage$hc_mortgage_mean), lwd=2, col=\"blue\", lty=\"dashed\")\n",
        "abline(v=median(sample_boost), lwd=2, col=\"black\", lty=\"dashed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdETMGxHUhY9"
      },
      "source": [
        "# We are 95% confident that the true median of the population is between 839 - 3180 of the mortgage cost.\n",
        "# This is a wide margin.\n",
        "quantile(sample_boost, probs=c(0.025, 0.975))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUM2EUQ3UhY9"
      },
      "source": [
        "### Mosaic Plots and Contingency Tables\n",
        "<a id=\"mosaic\"></a>\n",
        "---> Description Later:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CnpuphaUhY9"
      },
      "source": [
        "head(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0Xei6kEUhY-"
      },
      "source": [
        "<b> Note: </b> Puerto Rico is not a US state it is a US territory nevertheless, I added it to the region of the Caribbean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYR1e2RxUhY-"
      },
      "source": [
        "df$regions <- NA\n",
        "\n",
        "west <- c('CA', 'OR', 'UT','WA', 'CO', 'NV', 'AK', 'MT', 'HI', 'WY', 'ID')\n",
        "south_west <- c('AZ', 'TX', 'NM', 'OK')\n",
        "south_east <- c('GA', 'NC', 'VA', 'FL', 'KY', 'SC', 'LA', 'AL', 'WV', 'DC', 'AR', 'DE', 'MS', 'TN')\n",
        "mid_west <- c('IL','MO', 'MN', 'OH', 'WI', 'KS', 'MI', 'SD', 'IA', 'NE', 'IN', 'ND')\n",
        "north_east <- c('CT', 'NY', 'PA', 'NJ', 'RI','MA', 'MD', 'VT', 'NH', 'ME')\n",
        "\n",
        "df$regions <- with(df, ifelse(state_ab %in% west, \"West\", \n",
        "                              ifelse(state_ab %in% south_west, \"SouthWest\",\n",
        "                                    ifelse(state_ab %in% south_east, \"South East\",\n",
        "                                          ifelse(state_ab %in% mid_west, \"MidWest\",\n",
        "                                                ifelse(state_ab %in% north_east, \"NorthEast\", \n",
        "                                                       \"Caribbean\")))))) \n",
        "\n",
        "\n",
        "unique(df$regions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2-vMtbWUhY-"
      },
      "source": [
        "options(repr.plot.width=8, repr.plot.height=8)\n",
        "\n",
        "subset_rent <- df %>% filter(!is.na(rent_mean))\n",
        "\n",
        "\n",
        "ggplot(subset_rent, aes (x = rent_mean, fill= regions)) +\n",
        "  geom_histogram(aes(y=..density..), binwidth = 1) + scale_fill_brewer(palette=\"Dark2\") +\n",
        "facet_grid(regions~.) + theme_minimal() + theme(legend.position=\"None\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0DahM7yUhZA"
      },
      "source": [
        "# Create a COntingency table between the two categorical variables\n",
        "cont_table <- table(df$regions, df$type)\n",
        "\n",
        "# Let's create a frequency table\n",
        "\n",
        "freq_df <- apply(cont_table, 2, function(x) round(x/sum(x),2))\n",
        "                 \n",
        "# Change the structure of our frequency table.\n",
        "melt_df <- melt(freq_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-RhYuBDUhZA"
      },
      "source": [
        "names(melt_df) <- c(\"Regions\", \"Type\", \"Frequency\")\n",
        "\n",
        "\n",
        "ggplot(melt_df, aes(x = Type, y = Frequency, fill = Regions)) +\n",
        "  geom_col(position = \"stack\") +\n",
        "  facet_grid(Regions ~ .) + \n",
        "scale_fill_brewer(palette=\"Dark2\") + theme_minimal() + theme(legend.position=\"None\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqwePQRHUhZA"
      },
      "source": [
        "Mosaic plots helps us determine which categorical variables are <b> underrepresented </b> and <b> overrepresented </b> in relation to each other. A chi-squared test will be used later on to examine this relationship."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZFNvwiRUhZB"
      },
      "source": [
        "options(repr.plot.width=8, repr.plot.height=5)\n",
        "\n",
        "conti_df <- as.data.frame.matrix(table(df$regions, df$type))\n",
        "\n",
        "conti_df$groupSum <- rowSums(conti_df)\n",
        "conti_df$xmax <- cumsum(conti_df$groupSum)\n",
        "conti_df$xmin <- conti_df$xmax - conti_df$groupSum\n",
        "# The groupSum column needs to be removed; don't remove this line\n",
        "conti_df$groupSum <- NULL\n",
        "\n",
        "conti_df$regions <- rownames(conti_df)\n",
        "\n",
        "melt_df <- melt(conti_df, id.vars = c(\"regions\", \"xmin\", \"xmax\"), variable.name = \"type\")\n",
        "\n",
        "df_melt <- melt_df %>%\n",
        "  group_by(regions) %>%\n",
        "  mutate(ymax = cumsum(value/sum(value)),\n",
        "         ymin = ymax - value/sum(value))\n",
        "\n",
        "\n",
        "index <- df_melt$xmax == max(df_melt$xmax)\n",
        "df_melt$yposn <- df_melt$ymin[index] + (df_melt$ymax[index] - df_melt$ymin[index])/2\n",
        "\n",
        "\n",
        "df_melt$xposn <- df_melt$xmin + (df_melt$xmax - df_melt$xmin)/2\n",
        "\n",
        "# geom_text for ages (i.e. the x axis)\n",
        "\n",
        "\n",
        "\n",
        "p1<- ggplot(df_melt, aes(ymin = ymin,\n",
        "                 ymax = ymax,\n",
        "                 xmin = xmin,\n",
        "                 xmax = xmax,\n",
        "                 fill = type)) +\n",
        "  geom_rect(colour = \"white\") +\n",
        "  scale_x_continuous(expand = c(0,0)) +\n",
        "  scale_y_continuous(expand = c(0,0)) +\n",
        "  scale_fill_brewer(palette=\"RdBu\") +\n",
        "  theme_minimal() \n",
        "\n",
        "p1 + \n",
        "  geom_text(aes(x = xposn, label = regions),\n",
        "            y = 0.15, angle = 90,\n",
        "            size = 3, hjust = 1,\n",
        "            show.legend = FALSE) + labs(title=\"Mosaic Plot\") + theme(plot.title=element_text(hjust=0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESEnPrcjUhZB"
      },
      "source": [
        "### Detecting outliers through Standard Deviations:\n",
        "In this section, we will detect possible outliers. Although, I should mention that outliers should be carefully analyzed and individuals should be really carefull when it comes to deleting an observation in which that person believe a particular observation is an outlier.\n",
        "\n",
        "<b> Concepts to remember: </b>\n",
        "<ul>\n",
        "    <li> <b> Distribution: </b> It is recommended to use a normal distribution to detect outliers when using standard deviations.  </li>\n",
        "    <li><b>Standard deviation: </b>  If the standard deviation is 3 or greater we will consider it as an outlier.</li>\n",
        "    </ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "406n7KdzUhZB"
      },
      "source": [
        "options(repr.plot.width=8, repr.plot.height=3)\n",
        "\n",
        "# Let's look for normal distributed variables\n",
        "fem_age <- df %>% select(female_age_mean) %>% filter(!is.na(female_age_mean)) %>%\n",
        "ggplot(aes(x=female_age_mean)) + geom_histogram(binwidth=1, fill=\"red\") + theme_minimal()\n",
        "\n",
        "rent <- df %>% select(rent_mean) %>% filter(!is.na(rent_mean)) %>%\n",
        "ggplot(aes(x=rent_mean)) + geom_histogram(fill=\"blue\", binwidth=0.02) + \n",
        "scale_x_log10() + theme_minimal()\n",
        "\n",
        "plot_grid(fem_age, rent, align='h', ncol=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AezFlRFpUhZB"
      },
      "source": [
        "# Bivariate Analysis\n",
        "female_rent <- df %>% select(female_age_mean, rent_mean) %>% filter(!is.na(female_age_mean), !is.na(rent_mean))\n",
        "\n",
        "set.seed(1)\n",
        "small_sample <- female_rent %>% sample_n(100) \n",
        "\n",
        "ggplot(small_sample, aes(x=female_age_mean, y=rent_mean)) + geom_point(col=\"red\") + theme_minimal()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5e8DTnHUhZB"
      },
      "source": [
        "sample_std <- small_sample %>%\n",
        "  mutate(sd_female = (female_age_mean-mean(female_age_mean))/sd(female_age_mean),  \n",
        "         sd_rent = (rent_mean-mean(rent_mean))/sd(rent_mean))\n",
        "\n",
        "\n",
        "\n",
        "# The standard deviation how far is the value away from the mean and \n",
        "# Standard deviation for the rent.\n",
        "head(sample_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf74jvpnUhZB"
      },
      "source": [
        "### Up Next We will use these metrics to detect \"Possible outliers\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXsHTgB0UhZB"
      },
      "source": [
        "### Up Next: Understanding Chi-Squared Tests and Standarized Residuals: (This is still being updated)\n",
        "\n",
        "<img src=\"https://i.stack.imgur.com/H59e8.png\">\n",
        "\n",
        "Standardized residual = $\\frac{(observed\\ count – expected\\ count)} {\\sqrt{expected\\ count}}$<br>\n",
        "Expected Count = $\\frac{\\sum{data\\ in\\ row\\ + data\\ in\\ col}}{total\\ data}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Up5o5RUhZC"
      },
      "source": [
        "cont_table <- table(df$type, df$regions)\n",
        "#  Change to dataframe\n",
        "df_cont_table <- as.data.frame.matrix(cont_table)\n",
        "\n",
        "\n",
        "df_cont_table$Total <- colSums(df_cont_table)\n",
        "\n",
        "\n",
        "df_cont_table <- df_cont_table%>% adorn_totals(\"row\")\n",
        "\n",
        "\n",
        "df_cont_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6SzzYu-UhZC"
      },
      "source": [
        "# This simple test tells us there is a difference between these two columns (Low p-value.)\n",
        "results <- chisq.test(table(df$regions, df$type))\n",
        "\n",
        "resid <- melt(results$residuals)\n",
        "resid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvRmCeg2UhZC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIQRx7yeUhZC"
      },
      "source": [
        "### Visualizing US State Map with GGPlot2\n",
        "\n",
        "<a id=\"us_map\"></a>\n",
        "\n",
        "\n",
        "\n",
        "The goal of doing this visualization is to show the community a simple way for visualizing US maps using ggplot2 and the map library. This is useful when you would want to present visually which states or country had a high or low numeric variables.\n",
        "\n",
        "**Summary of Findings:**\n",
        "<ul>\n",
        "    <li>States with Average high divorce rates: States with high divorce rates include Nevada, Oklahoma, Arkansas and West Virginia.</li>\n",
        "    <li>States with Average low divorce rates: States with low divorce rates include California, Utah, New York and New Jersey </li>\n",
        "</ul>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d20Y_TuOUhZC"
      },
      "source": [
        "options(repr.plot.height = 8)\n",
        "\n",
        "\n",
        "us_map <- map_data(\"state\") %>% \n",
        "as_tibble()\n",
        "\n",
        "\n",
        "us_map %>%\n",
        "ggplot(aes(long, lat, map_id = region)) + \n",
        "geom_map(\n",
        "    map =us_map,\n",
        "    color = \"gray80\",\n",
        "    fill = \"gray30\",\n",
        "    size = 0.3\n",
        ") + \n",
        "coord_map(\"ortho\", orientation = c(39, -98, 0)) + \n",
        "labs(\n",
        "    title = \"US Map\",\n",
        "    subtitle = \"Based on Latitude and Longitude\"\n",
        ") + theme(plot.title = element_text(hjust=0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGKzp99oUhZC"
      },
      "source": [
        "# Highest percent of divorced by state on average\n",
        "\n",
        "\n",
        "\n",
        "# First we will need to join tables\n",
        "divorced_tbl <- df %>% select(state, state_ab, divorced) %>%\n",
        "group_by(state, state_ab) %>%\n",
        "summarise(\n",
        "    avg_div_rate = mean(divorced, na.rm=TRUE),\n",
        "    avg_div_txt = scales::percent(avg_div_rate)\n",
        ") %>% \n",
        "ungroup() %>% \n",
        "mutate(state = str_to_lower(state)) %>%\n",
        "left_join(us_map, by=c(\"state\" = \"region\"))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwKeaOPzUhZD"
      },
      "source": [
        "\n",
        "\n",
        "divorced_tbl %>%\n",
        "ggplot(aes(long, lat, group = subregion)) + \n",
        "geom_map(\n",
        "    aes(map_id = state),\n",
        "    map = us_map,\n",
        "    color = \"gray80\",\n",
        "    fill = \"gray30\",\n",
        "    size=0.3\n",
        ") + coord_map(\"ortho\", orientation = c(39, -98, 0)) + geom_polygon(aes(group = group, fill = avg_div_rate), color=\"black\") +\n",
        "scale_fill_gradient2(\"\",low = \"#18BC9C\", mid = \"white\", high = \"#E31A1C\", midpoint = 0.10, labels = scales::percent) + \n",
        "theme_minimal() + \n",
        "theme(\n",
        "    plot.title = element_text(size=18, face=\"bold\", color = \"#2C3E50\"),\n",
        "    legend.position = \"right\"\n",
        ") + \n",
        "labs(\n",
        "    title = \"Divorce Rates across US States\",\n",
        "    x = \"\",\n",
        "    y = \"\"\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mboMPRGTUhZD"
      },
      "source": [
        "# Percent divorced by region\n",
        "suppressMessages(library(tidyquant))\n",
        "\n",
        "options(repr.plot.height = 5)\n",
        "\n",
        "div_rates <- df %>%\n",
        "select(regions, divorced) %>%\n",
        "group_by(regions) %>%\n",
        "summarise(\n",
        "    avg_div_rate = mean(divorced, na.rm=TRUE)\n",
        ") %>%\n",
        "ungroup() %>%\n",
        "mutate(\n",
        "    regions = regions %>% as_factor() %>% fct_reorder(avg_div_rate)\n",
        ")\n",
        "\n",
        "div_rates %>%\n",
        "ggplot(aes(x=regions, y=avg_div_rate, fill=regions)) + geom_col(color=\"black\") + theme_minimal() + scale_fill_tq() + \n",
        "theme(legend.position=\"bottom\") + geom_label(aes(label=scales::percent(avg_div_rate)), color=\"white\") + \n",
        "labs(\n",
        "    title = \"Divorce Rates by Region\",\n",
        "    y = \"Divorce Rates\", \n",
        "    x = \"Regions\"\n",
        ") + coord_flip() + scale_y_continuous(labels = scales::percent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E83Wy-UYUhZD"
      },
      "source": [
        "\n",
        "\n",
        "heatmap_tbl <- df %>%\n",
        "select(regions, state, type, divorced) %>%\n",
        "group_by(regions, type) %>%\n",
        "summarise(\n",
        "    avg_div_rate = mean(divorced, na.rm=TRUE)\n",
        ") %>% ungroup() %>%\n",
        "mutate(\n",
        "    regions = regions %>% as_factor %>% fct_rev()\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "heatmap_tbl %>%\n",
        "ggplot(aes(type, regions)) + \n",
        "geom_tile(aes(fill=avg_div_rate)) + scale_fill_gradient2(low=palette_light()[1], \n",
        "                                                         mid=\"white\", \n",
        "                                                         high = palette_light()[2], \n",
        "                                                         midpoint=0.10) + facet_wrap(~type) + theme_minimal() + \n",
        "theme(legend.position=\"none\", axis.text.x = element_text(angle=45, hjust=1)) + geom_text(aes(label = scales::percent(avg_div_rate)), size=2.5) + \n",
        "labs(\n",
        "    fill = \"\",\n",
        "    title = \"Divorce by type in grouped by region\"\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi6TKIGWUhZD"
      },
      "source": [
        "### Statistical Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNxHLSIwUhZD"
      },
      "source": [
        "prepared_df <- df %>% select(regions, type, divorced, separated, married)\n",
        "\n",
        "\n",
        "long_tbl <- prepared_df %>%\n",
        "gather(key = \"status\", value = \"measurement\", divorced:married)\n",
        "\n",
        "# Balloon Plot\n",
        "ggballoonplot(long_tbl, x = \"type\", y = \"regions\",\n",
        "              size = \"measurement\", fill = \"measurement\", facet.by = \"status\", shape = 21,  ggtheme=theme_minimal()) +\n",
        "   scale_fill_gradient2(low = \"#2E604A\", mid = \"white\", high = \"#D1362F\") +\n",
        "  guides(size = FALSE) + \n",
        "labs(\n",
        "    title = \"Rate by Marital Status\"\n",
        "  ) + \n",
        "  theme(panel.grid.major = element_blank(),\n",
        "        axis.text.x = element_text(size = 14),\n",
        "        plot.title = element_text(face = \"bold\"),\n",
        "        plot.subtitle = element_text(face = \"bold\"),\n",
        "        axis.ticks = element_blank()) + \n",
        "geom_tile(color = \"black\", fill = \"transparent\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lfpq4GjUhZD"
      },
      "source": [
        "library(wesanderson)\n",
        "\n",
        "\n",
        "long_tbl %>%\n",
        "gghistogram(x=\"measurement\", color = \"status\", fill=\"status\", palette= wes_palette(\"Moonrise2\"), add=\"mean\") + \n",
        "ggtitle(\"Distribution of Status\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8P87d9wUhZD"
      },
      "source": [
        "# Factor will be regions\n",
        "# x will be debt\n",
        "# y will be rent_mean \n",
        "# Is debt higher where rent is higher\n",
        "# Which regions have the highest level of rent and debt\n",
        "\n",
        "\n",
        "prepared_tbl <- df %>% select(regions, type, rent_mean, debt) %>%\n",
        "group_by(regions, type) %>%\n",
        "summarise(\n",
        "    rent_mean = mean(rent_mean, na.rm=TRUE),\n",
        "    debt_mean = mean(debt, na.rm=TRUE)\n",
        ") %>% ungroup()\n",
        "\n",
        "\n",
        "ggscatter(prepared_tbl, x = \"rent_mean\", y = \"debt_mean\",\n",
        "          color = \"regions\", palette = \"jco\",           \n",
        "          shape = \"regions\") \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}